<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="AffectiveTweets Documentation">
  
  <link rel="shortcut icon" href="./img/favicon.ico">
  <title>Home - AffectiveTweets</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="./css/theme.css" type="text/css" />
  <link rel="stylesheet" href="./css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="./css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Home";
    var mkdocs_page_input_path = "index.md";
    var mkdocs_page_url = "/";
  </script>
  
  <script src="./js/jquery-2.1.1.min.js"></script>
  <script src="./js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="./js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="." class="icon icon-home"> AffectiveTweets</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1 current">
		
    <a class="current" href=".">Home</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#about">About</a></li>
    

    <li class="toctree-l2"><a href="#relevant-papers">Relevant Papers</a></li>
    

    <li class="toctree-l2"><a href="#citation">Citation</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#filters">Filters</a></li>
        
            <li><a class="toctree-l3" href="#distant-supervision-filters">Distant Supervision Filters</a></li>
        
            <li><a class="toctree-l3" href="#tokenizers">Tokenizers</a></li>
        
            <li><a class="toctree-l3" href="#other-resources">Other Resources</a></li>
        
        </ul>
    

    <li class="toctree-l2"><a href="#team">Team</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#main-developer">Main Developer</a></li>
        
            <li><a class="toctree-l3" href="#contributors">Contributors:</a></li>
        
        </ul>
    

    <li class="toctree-l2"><a href="#contact">Contact</a></li>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="install/">Installation</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="examples/">Examples</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href=".">AffectiveTweets</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".">Docs</a> &raquo;</li>
    
      
    
    <li>Home</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/felipebravom/AffectiveTweets/edit/master/docs/index.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <p><img src="img/logo.png" alt="alt text" width="30%" height="30%"> </p>
<h2 id="about">About</h2>
<p><a href="http://weka.sourceforge.net/packageMetaData/AffectiveTweets/index.html">AffectiveTweets</a> is a <a href="http://www.cs.waikato.ac.nz/~ml/weka/">WEKA</a> package for analyzing emotion and sentiment of English written tweets. </p>
<p>The package implements WEKA filters for calculating state-of-the-art affective analysis features from tweets that can be fed into machine learning algorithms. Many of these features were drawn from the <a href="http://saifmohammad.com/WebPages/NRC-Canada-Sentiment.htm">NRC-Canada System</a>. It also implements methods for building affective lexicons and distant supervision methods for training affective models from unlabelled tweets.</p>
<p>The package was also made available as the official baseline system for the <a href="http://optima.jrc.it/wassa2017/">WASSA-2017</a> Shared Task on Emotion Intensity <a href="http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html">(EmoInt)</a>. (Instructions for using the system with the task data are available <a href="https://github.com/felipebravom/EmoInt#2-weka-baseline-system">here</a>.) Five participating teams used AffectiveTweets to generate feature vectors, including the teams that eventually ranked first, second, and third. </p>
<p>The Java documentation is available <a href="https://felipebravom.github.io/AffectiveTweets/doc/index.html">here</a>.</p>
<p>Description about the filters, installation instructions, and examples are given below.</p>
<h2 id="relevant-papers">Relevant Papers</h2>
<p>The most relevant papers on which this package is based are:</p>
<ul>
<li><a href="http://saifmohammad.com/WebDocs/NRC-Sentiment-JAIR-2014.pdf">Sentiment Analysis of Short Informal Texts</a>. Svetlana Kiritchenko, Xiaodan Zhu and Saif Mohammad. Journal of Artificial Intelligence Research, volume 50, pages 723-762, August 2014. <a href="http://saifmohammad.com/WebDocs/JAIR14-bibtex.txt">BibTeX</a></li>
<li><a href="http://www.sciencedirect.com/science/article/pii/S0950705114002068">Meta-Level Sentiment Models for Big Social Data Analysis</a>. F. Bravo-Marquez, M. Mendoza and B. Poblete. Knowledge-Based Systems Volume 69, October 2014, Pages 86â€“99. <a href="http://dblp.uni-trier.de/rec/bib2/journals/kbs/Bravo-MarquezMP14.bib">BibTex</a></li>
<li><a href="http://saifmohammad.com/WebDocs/1605.01655v1.pdf">Stance and sentiment in tweets</a>. Saif M. Mohammad, Parinaz Sobhani, and Svetlana Kiritchenko. 2017. Special Section of the ACM Transactions on Internet Technology on Argumentation in Social Media 17(3). <a href="http://saifmohammad.com/WebPages/Abstracts/stance-toit.bib.txt">BibTeX</a></li>
<li><a href="http://dl.acm.org/citation.cfm?id=2336261">Sentiment strength detection for the social Web</a>. Thelwall, M., Buckley, K., &amp; Paltoglou, G. (2012). Journal of the American Society for Information Science and Technology, 63(1), 163-173. <a href="http://dblp.uni-trier.de/rec/bib2/journals/jasis/ThelwallBP12.bib">BibTex</a></li>
</ul>
<h2 id="citation">Citation</h2>
<p>Please cite the following paper if using this package in an academic publication:</p>
<ul>
<li><strong>Emotion Intensities in Tweets</strong>. Saif M. Mohammad and Felipe Bravo-Marquez. In Proceedings of the Joint Conference on Lexical and Computational Semantics (*Sem), August 2017, Vancouver, Canada. </li>
</ul>
<p>You should also cite the papers describing any of the lexicons or resources you are using with this package. The corresponding references can be found through the links provided below.</p>
<h3 id="filters">Filters</h3>
<h4 id="tweet-level-filters">Tweet-level Filters</h4>
<ol>
<li><strong>TweetToSparseFeatureVector</strong>: calculates sparse features, such as word and character n-grams from tweets. There are parameters for filtering out infrequent features e.g., (n-grams occurring in less than <em>m</em> tweets) and for setting the weighting approach  (boolean or frequency based).</li>
<li><strong>Word n-grams</strong>: extracts word n-grams from <em>n</em>=1 to a maximum value. </li>
<li><strong>Negations</strong>: add a prefix to words occurring in negated contexts, e.g., I don't like you =&gt; I don't NEG-like NEG-you. The prefixes only affect word n-gram features. The scope of negation finishes with the next punctuation expression <em>([\.|,|:|;|!|\?]+)</em> .</li>
<li><strong>Character n-grams</strong>: calculates character n-grams.</li>
<li><strong>POS tags</strong>: tags tweets using the <a href="http://www.cs.cmu.edu/~ark/TweetNLP/">CMU Tweet NLP tool</a>, and creates a vector space model based on the sequence of POS tags. <a href="http://dblp.uni-trier.de/rec/bib2/conf/acl/GimpelSODMEHYFS11.bib">BibTex</a></li>
<li>
<p><strong>Brown clusters</strong>: maps the words in a tweet to Brown word clusters and creates a low-dimensional vector space model. It can be used with n-grams of word clusters. The word clusters are also taken from the <a href="http://www.cs.cmu.edu/~ark/TweetNLP/">CMU Tweet NLP tool</a>.</p>
</li>
<li>
<p><strong>TweetToLexiconFeatureVector</strong>: calculates features from a tweet using several lexicons.</p>
</li>
<li><a href="http://mpqa.cs.pitt.edu/lexicons/subj_lexicon">MPQA</a>: counts the number of positive and negative words from the MPQA subjectivity lexicon. <a href="http://dblp.uni-trier.de/rec/bib2/conf/naacl/WilsonWH05.bib">BibTex</a></li>
<li><a href="https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon">Bing Liu</a>: counts the number of positive and negative words from the Bing Liu lexicon. <a href="http://dblp.uni-trier.de/rec/bib2/conf/kdd/HuL04.bib">BibTex</a></li>
<li><a href="https://github.com/fnielsen/afinn">AFINN</a>: calculates positive and negative variables by aggregating the positive and negative word scores provided by this lexicon. <a href="http://dblp.uni-trier.de/rec/bib2/conf/msm/Nielsen11.bib">BibTex</a></li>
<li><a href="http://saifmohammad.com/WebPages/lexicons.html#NRCTwitter">Sentiment140</a>: calculates positive and negative variables by aggregating the positive and negative word scores provided by this lexicon created with tweets annotated by emoticons. <a href="http://saifmohammad.com/WebDocs/JAIR14-bibtex.txt">BibTex</a></li>
<li><a href="http://saifmohammad.com/WebPages/lexicons.html#NRCTwitter">NRC Hashtag Sentiment lexicon</a>: calculates positive and negative variables by aggregating the positive and negative word scores provided by this lexicon created with tweets annotated with emotional hashtags. <a href="http://saifmohammad.com/WebDocs/JAIR14-bibtex.txt">BibTex</a> </li>
<li><a href="http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm">NRC Word-Emotion Association Lexicon</a>: counts the number of words matching each emotion from this lexicon. <a href="http://saifmohammad.com/WebPages/Abstracts/crowdemo.bib.txt">BibTex</a></li>
<li><a href="http://www.cs.waikato.ac.nz/ml/sa/lex.html#emolextwitter">NRC-10 Expanded</a>: adds the emotion associations of the words matching the Twitter Specific expansion of the NRC Word-Emotion Association Lexicon. <a href="http://dblp.uni-trier.de/rec/bib2/conf/webi/Bravo-MarquezFM16.bib">BibTex</a></li>
<li><a href="http://saifmohammad.com/WebPages/lexicons.html#HashEmo">NRC Hashtag Emotion Association Lexicon</a>: adds the emotion associations of the words matching this lexicon. <a href="http://saifmohammad.com/WebPages/hashtagPersonality-bib.html">BibTex</a>  </li>
<li><a href="http://sentiwordnet.isti.cnr.it">SentiWordNet</a>: calculates positive and negative scores using SentiWordnet. We calculate a weighted average of the sentiment distributions of the synsets for word occurring in multiple synsets. The weights correspond to the reciprocal ranks of the senses in order to give higher weights to most popular senses. <a href="http://dblp.uni-trier.de/rec/bib2/conf/lrec/BaccianellaES10.bib">BibTex</a> </li>
<li><a href="https://github.com/fnielsen/afinn">Emoticons</a>: calculates a positive and a negative score by aggregating the word associations provided by a list of emoticons. The list is taken from the <a href="https://github.com/fnielsen/afinn">AFINN</a> project.</li>
<li>
<p>Negations: counts the number of negating words in the tweet.</p>
</li>
<li>
<p><strong>TweetToInputLexiconFeatureVector</strong> (new): calculates features from a tweet using a given list of affective lexicons, where each lexicon is represented as an <a href="https://weka.wikispaces.com/ARFF">ARFF</a> file.  The features are calculated by adding or counting the affective associations of the words matching the given lexicons. All numeric and nominal attributes from each lexicon are considered. Numeric scores are added and nominal are counted. The <a href="http://www.saifmohammad.com/WebPages/AffectIntensity.htm">NRC-Affect-Intensity</a> lexicon is used by deault. (This is filter is only available with the new version of the package).  <a href="http://dblp.uni-trier.de/rec/bib2/journals/corr/Mohammad17.bib">BibTex</a></p>
</li>
<li>
<p><strong>TweetToSentiStrengthFeatureVector</strong>: calculates positive and negative sentiment strengths for a tweet using <a href="http://sentistrength.wlv.ac.uk/">SentiStrength</a>. Disclaimer: <strong>SentiStrength</strong> can only be used for academic purposes from within this package. <a href="http://dblp.uni-trier.de/rec/bib2/journals/jasis/ThelwallBP12.bib">BibTex</a></p>
</li>
<li>
<p><strong>TweetToEmbeddingsFeatureVector</strong>: calculates a tweet-level feature representation using pre-trained word embeddings. A dummy word-embedding formed by zeroes is used for word with no corresponding embedding. The tweet vectors can be calculated using the following schemes: </p>
</li>
<li>
<p>Average word embeddings.</p>
</li>
<li>Add word embeddings. </li>
<li>Concatenation of first <em>k</em> embeddings. Dummy values are added if the tweet has less than <em>k</em> words. </li>
</ol>
<h4 id="word-level-filters">Word-level Filters</h4>
<ol>
<li>
<p><strong>PMILexiconExpander</strong>: calculates the Pointwise Mutual Information (PMI) semantic orientation for each word in a corpus of tweets annotated by sentiment. The score is calculated by substracting the PMI of the  target  word  with  a negative  sentiment from the PMI of the target word with a positive sentiment. This is a supervised filter.  <a href="http://dblp.uni-trier.de/rec/bib2/conf/acl/Turney02.bib">BibTex</a> </p>
</li>
<li>
<p><strong>TweetCentroid</strong>:  calculates word distributional vectors from a corpus of unlabelled tweets by treating them as the centroid of the tweet vectors in which they appear. The vectors can be labelled using an affective lexicon to train a word-level affective classifier. This classifier can be used to expand the original lexicon.  <a href="http://dblp.uni-trier.de/rec/bib2/conf/sigir/Bravo-MarquezFP15.bib">BibTex</a>, <a href="http://www.cs.waikato.ac.nz/~fbravoma/publications/sigir15.pdf">original paper</a></p>
</li>
<li>
<p><strong>LabelWordVectors</strong>: labels word vectors with an input lexicon in arff format. This filter is useful for training word-level affective classifiers.</p>
</li>
</ol>
<h3 id="distant-supervision-filters">Distant Supervision Filters</h3>
<ol>
<li><strong>ASA</strong>:  Annotate-Sample-Average (ASA) is a lexical-based distant supervision method for training polarity classifiers in Twitter in the absence of labelled data. It takes a collection of unlabelled tweets and a polarity lexicon in arff format and creates synthetic labelled instances. Each labelled instance is created by sampling with replacement a number of tweets containing at least one word from the lexicon with the desired polarity, and averaging the feature vectors of the sampled tweets.  <a href="http://dblp.uni-trier.de/rec/bib2/conf/ecai/Bravo-MarquezFP16.bib">BibTex</a>, <a href="http://www.cs.waikato.ac.nz/~fbravoma/publications/ecai2016.pdf">original paper</a></li>
</ol>
<h3 id="tokenizers">Tokenizers</h3>
<ol>
<li><strong>TweetNLPTokenizer</strong>: a Twitter-specific String tokenizer based on the <a href="http://www.cs.cmu.edu/~ark/TweetNLP/">CMU Tweet NLP tool</a> that can be used with the existing <a href="http://weka.sourceforge.net/doc.dev/weka/filters/unsupervised/attribute/StringToWordVector.html">StringWordToVector</a> Weka filter. </li>
</ol>
<h3 id="other-resources">Other Resources</h3>
<ol>
<li><strong>Datasets</strong>: The package provides some tweets annotated by affective values in gzipped <a href="http://weka.wikispaces.com/ARFF">ARFF</a> format in $WEKA_HOME/packages/AffectiveTweets/data/. The default location for $WEKA_HOME is $HOME/wekafiles. </li>
<li>
<p><strong>Affective Lexicons</strong>: The package provides affective lexicons in <a href="http://weka.wikispaces.com/ARFF">ARFF</a> format. These lexicons are located in $WEKA_HOME/packages/AffectiveTweets/lexicons/arff_lexicons/ and can be used with the  <strong>TweetToInputLexiconFeatureVector</strong> filter.</p>
</li>
<li>
<p><strong>Pre-trained Word-Embeddings</strong>: The package provides a file with pre-trained word vectors trained with the <a href="https://code.google.com/archive/p/word2vec/">Word2Vec</a> tool in gzip compressed format. It is a tab separated file with the word in last column located in $WEKA_HOME/packages/AffectiveTweets/resources/w2v.twitter.edinburgh.100d.csv.gz. However, this is a toy example trained from a small collection of tweets. We recommend downloading <a href="https://github.com/felipebravom/AffectiveTweets/releases/download/1.0.0/w2v.twitter.edinburgh10M.400d.csv.gz">w2v.twitter.edinburgh10M.400d.csv.gz</a>, which provides  embeddings trained from 10 million tweets taken from the <a href="http://www.aclweb.org/anthology/W/W10/W10-0513.pdf">Edinburgh corpus</a>. The parameters were calibrated for classifying words into emotions. More info in this <a href="http://www.cs.waikato.ac.nz/~fjb11/publications/wi2016a.pdf">paper</a>.</p>
</li>
</ol>
<h2 id="team">Team</h2>
<h3 id="main-developer">Main Developer</h3>
<ul>
<li><a href="http://www.cs.waikato.ac.nz/~fbravoma/">Felipe Bravo-Marquez</a>.</li>
</ul>
<h3 id="contributors">Contributors:</h3>
<ul>
<li><a href="http://saifmohammad.com/">Saif Mohammad</a></li>
<li><a href="http://www.cs.waikato.ac.nz/~eibe/">Eibe Frank</a></li>
<li><a href="https://www.cs.auckland.ac.nz/people/b-pfahringer">Bernhard Pfahringer</a></li>
</ul>
<p>New contributors are more than welcome!</p>
<h2 id="contact">Contact</h2>
<ul>
<li>Email: fbravoma at waikato.ac.nz</li>
<li>If you have questions about Weka please refer to the Weka <a href="https://list.waikato.ac.nz/mailman/listinfo/wekalist">mailing list</a>. </li>
</ul>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="install/" class="btn btn-neutral float-right" title="Installation">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/felipebravom/AffectiveTweets" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
      
        <span style="margin-left: 15px"><a href="install/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="./js/theme.js"></script>

</body>
</html>

<!--
MkDocs version : 0.16.3
Build Date UTC : 2017-10-17 01:29:08
-->
